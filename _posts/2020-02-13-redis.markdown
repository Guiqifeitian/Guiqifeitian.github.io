---
title: "redis"
layout: post
date: "2020-02-13 09:58:18"
categories: blog
published: True
tags: "code"
---

### redis.py

StrictRedis实现了大部分的官方命令，Redis是StrictRedis的子类，用于向后兼容旧版本的redis.py

```python
import redis
conn = redis.Redis(host='127.0.0.1', port=6379)
# 可以使用url方式连接到数据库
# conn = Redis.from_url('redis://@localhost:6379/1')
conn.set('name', 'LinWOW')
print(conn.get('name'))
```

### 部署方式

使用容器部署

```
docker run --name some-redis -d redis:4.0 redis-server --appendonly yes
```

### 常用命令

```
config get requirepass #查询是否设置访问密码
config set requirepass mypassword #设置访问密码
auth mypassword #认证密码
keys * #查询所有键值
```

### 配置文件

可以在部署redis的时候，手动指定redis的配置文件路径，在启动redis后，通过redis-cli，可以使用命令`config get *`获取所有配置信息

```
bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP

protected-mode yes #redis3.2 之后加入的新特性，在没有设置bind IP和密码的时候,redis只允许访问127.0.0.1:6379，可以远程连接，但当访问将提示警告信息并拒绝远程访问

port 6379 #监听端口

tcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值，即全队列长度

timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时

tcp-keepalive 300 #tcp 会话保持时间300s

daemonize no #默认redis-server不作为守护进程运行的，而前台运行，如果想在后台运行，就把它改成 yes,当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件

supervised no #和OS相关参数，可设置通过upstart和systemd管理Redis守护进程，centos7后都使用systemd

pidfile /var/run/redis_6379.pid #pid文件路径

loglevel notice #日志级别

logfile "/path/redis.log" #日志路径

databases 16 #设置数据库数量，默认：0-15，共16个库

always-show-logo yes #在启动redis 时是否显示redis的logo

save 900 1 #在900秒内有一个键内容发生更改就出就快照机制
save 300 10
save 60 10000  #60秒内如果有10000个健以上的变化，就自动快照备份

stop-writes-on-bgsave-error yes #yes时因空间满等原因快照无法保存出错时，禁止redis写入操作，建议为no

rdbcompression yes #持久化到RDB文件时，是否压缩，"yes"为压缩，"no"则反之

rdbchecksum yes #是否对备份文件开启RC64校验，默认是开启

dbfilename dump.rdb #快照文件名

dir ./ #快照文件保存路径，示例：dir "/apps/redis/data"

# replicaof <masterip> <masterport>  #指定复制的master主机地址和端口，5.0版之前的指令为slaveof 
# masterauth <master-password> #指定复制的master主机的密码

replica-serve-stale-data yes #当从库同主库失去连接或者复制正在进行，从机库有两种运行方式：
1、设置为yes(默认设置)，从库会继续响应客户端的读请求，此为建议值
2、设置为no，除去指定的命令之外的任何请求都会返回一个错误"SYNC with master in progress"。

replica-read-only yes #是否设置从库只读，建议值为yes,否则主库同步从库时可能会覆盖数据，造成数据丢失

repl-diskless-sync no #是否使用socket方式复制数据(无盘同步)，新slave连接连接时候需要做数据的全量同步，redis server就要从内存dump出新的RDB文件，然后从master传到slave，有两种方式把RDB文件传输给客户端：
1、基于硬盘（disk-backed）：为no时，master创建一个新进程dump生成RDB磁盘文件，RDB完成之后由父进程（即主进程）将RDB文件发送给slaves，此为推荐值
2、基于socket（diskless）：master创建一个新进程直接dump RDB至slave的网络socket，不经过主进程和硬盘

基于硬盘（为no），RDB文件创建后，一旦创建完毕，可以同时服务更多的slave，但是基于socket(为yes)， 新slave连接到master之后得逐个同步数据。当磁盘I/O较慢且网络较快时，可用diskless(yes),否则使用磁盘(no)

repl-diskless-sync-delay 5 #diskless时复制的服务器等待的延迟时间，设置0为关闭，在延迟时间内到达的客户端，会一起通过diskless方式同步数据，但是一旦复制开始，master节点不会再接收新slave的复制请求，直到下一次同步开始才再接收新请求。即无法为延迟时间后到达的新副本提供服务，新副本将排队等待下一次RDB传输，因此服务器会等待一段时间才能让更多副本到达。推荐值：30-60

repl-ping-replica-period 10 #slave根据master指定的时间进行周期性的PING master 监测master状态

repl-timeout 60 #复制连接的超时时间，需要大于repl-ping-slave-period，否则会经常报超时

repl-disable-tcp-nodelay no #是否在slave套接字发送SYNC之后禁用 TCP_NODELAY，如果选择"yes"，Redis将合并多个报文为一个大的报文，从而使用更少数量的包向slaves发送数据，但是将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒，如果 "no" ，数据传输到slave的延迟将会减少，但要使用更多的带宽

repl-backlog-size 512mb #复制缓冲区内存大小，当slave断开连接一段时间后，该缓冲区会累积复制副本数据，因此当slave 重新连接时，通常不需要完全重新同步，只需传递在副本中的断开连接后没有同步的部分数据即可。只有在至少有一个slave连接之后才分配此内存空间。

repl-backlog-ttl 3600 #多长时间内master没有slave连接，就清空backlog缓冲区

replica-priority 100 #当master不可用，Sentinel会根据slave的优先级选举一个master，此值最低的slave会当选master，而配置成0，永远不会被选举，一般多个slave都设为一样的值，让其自动选择

#min-replicas-to-write 3  #至少有3个可连接的slave，mater才接受写操作
#min-replicas-max-lag 10  #和上面至少3个slave的ping延迟不能超过10秒，否则master也将停止写操作

requirepass foobared #设置redis 连接密码，如果有特殊符号，用" "引起来

rename-command #重命名一些高危命令，示例：rename-command FLUSHALL "" 禁用命令

maxclients 10000 #Redis最大连接客户端

maxmemory #redis使用的最大内存，单位为bytes字节，0为不限制，建议设为物理内存一半，8G内存的计算方式8(G)*1024(MB)1024(KB)*1024(Kbyte)，需要注意的是缓冲区是不计算在maxmemory内。

appendonly no #是否开启AOF日志记录，默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了，但是redis如果中途宕机，会导致可能有几分钟的数据丢失(取决于dumpd数据的间隔时间)，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性，Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。默认不启用此功能

appendfilename "appendonly.aof" #AOF文件名，是文本文件，存放在dir指令指定的目录中
appendfsync everysec #aof持久化策略的配置,no表示不执行fsync，由操作系统保证数据同步到磁盘,always表示每次写入都执行fsync，以保证数据同步到磁盘,everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。

no-appendfsync-on-rewrite no #在aof rewrite期间,是否对aof新记录的append暂缓使用文件同步策略,主要考虑磁盘IO开支和请求阻塞时间。默认为no,表示"不暂缓",新的aof记录仍然会被立即同步，Linux的默认fsync策略是30秒，如果为yes 可能丢失30秒数据，但由于yes性能较好而且会避免出现阻塞因此比较推荐。

auto-aof-rewrite-percentage 100 # 当Aof log增长超过指定百分比例时，重写AOF文件， 设置为0表示不自动重写Aof 日志，重写是为了使aof体积保持最小，但是还可以确保保存最完整的数据

auto-aof-rewrite-min-size 64mb #触发aof rewrite的最小文件大小

aof-load-truncated yes #是否加载由于其他原因导致的末尾异常的AOF文件(主进程被kill/断电等)，建议yes

aof-use-rdb-preamble yes #redis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF格式的内存则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点（既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）。

lua-time-limit 5000 #lua脚本的最大执行时间，单位为毫秒

cluster-enabled yes #是否开启集群模式，默认是单机模式

cluster-config-file nodes-6379.conf #由node节点自动生成的集群配置文件名称

cluster-node-timeout 15000 #集群中node节点连接超时时间，超过此时间，会踢出集群

cluster-replica-validity-factor 10 #在执行故障转移的时候可能有些节点和master断开一段时间数据比较旧，这些节点就不适用于选举为master，超过这个时间的就不会被进行故障转移，计算公式：(node-timeout * replica-validity-factor) + repl-ping-replica-period 

cluster-migration-barrier 1 #集群迁移屏障，一个主节点至少拥有一个正常工作的从节点，即如果主节点的slave节点故障后会将多余的从节点分配到当前主节点成为其新的从节点。

cluster-require-full-coverage yes #集群请求槽位全部覆盖，如果一个主库宕机且没有备库就会出现集群槽位不全，那么yes情况下redis集群槽位验证不全就不再对外提供服务，而no则可以继续使用但是会出现查询数据查不到的情况(因为有数据丢失)。建议为no

cluster-replica-no-failover no #如果为yes,此选项阻止在主服务器发生故障时尝试对其主服务器进行故障转移。 但是，主服务器仍然可以执行手动强制故障转移，一般为no

#Slow log 是 Redis 用来记录超过指定执行时间的日志系统， 执行时间不包括与客户端交谈，发送回复等I/O操作，而是实际执行命令所需的时间（在该阶段线程被阻塞并且不能同时为其它请求提供服务）slow log 保存在内存里面，读写速度非常快，因此可放心地使用，不必担心因为开启 slow log 而影响 Redis 的速度

slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作。

slowlog-max-len 128 #最多记录多少条慢日志的保存队列长度，达到此长度后，记录新命令会将最旧的命令从命令队列中删除，以此滚动删除

127.0.0.1:6379> SLOWLOG len  #查看慢日志的记录条数
(integer) 14
127.0.0.1:6379> slowlog get  #查看慢日志的记录
1) 1) (integer) 14
2) (integer) 1544690617
3) (integer) 4
4) 1) "slowlog"
127.0.0.1:6379> SLOWLOG reset #清空慢日志
OK
```

### 持久化



